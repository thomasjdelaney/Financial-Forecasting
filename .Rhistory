library(M4comp2018)
library(TSPred)
plotForecastVsActual <- function(series){
forecast_data <- tail(c(series$x, series$y_hat), 5*series$h)
actual_data <- tail(c(series$x, series$xx), 5*series$h)
y_limits <- c(min(c(forecast_data, actual_data)), max(c(forecast_data, actual_data)))
series_title <- paste(series$st, "Price")
plot(forecast_data, type="l", col="blue", ylim = y_limits, ylab = series_title)
lines(actual_data, type="l", col="black")
}
calcMDapes <- function(series){
series_mape <- median(abs((series$xx - series$y_hat)/series$xx))
rw_drift_mape <- median(abs((series$xx - series$ff["rw_drift_forec",])/series$xx))
arima_mape <- median(abs((series$xx - series$ff["auto_arima_forec",])/series$xx))
ets_mape <- median(abs((series$xx - series$ff["ets_forec",])/series$xx))
nn_mape <- median(abs((series$xx - series$ff["nnetar_forec",])/series$xx))
tbats_mape <- median(abs((series$xx - series$ff["tbats_forec",])/series$xx))
stlm_mape <- median(abs((series$xx - series$ff["stlm_ar_forec",])/series$xx))
thetaf_mape <- median(abs((series$xx - series$ff["thetaf_forec",])/series$xx))
naive_mape <- median(abs((series$xx - series$ff["naive_forec",])/series$xx))
snaive_mape <- median(abs((series$xx - series$ff["snaive_forec",])/series$xx))
series_frame <- data.frame(series_name = series$st,
meta_mape = series_mape,
rw_drift_mape = rw_drift_mape,
arima_mape = arima_mape,
ets_mape = ets_mape,
nn_mape = nn_mape,
tbats_mape = tbats_mape,
stlm_mape = stlm_mape,
thetaf_mape = thetaf_mape,
naive_mape = naive_mape,
snaive_mape = snaive_mape)
return(series_frame)
}
# Setting up globals ####
isfin <- sapply(M4, function(time_series) time_series$type == "Finance")
fin_inds <- which(isfin)
num_fin_time_series <- length(fin_inds)
set.seed(1202)
indices <- sample(num_fin_time_series)
test_inds <- indices[20001:24534]
test <- readRDS("./rds/augmented_M4_financial_test_daily.rds")
test_data <- create_feat_classif_problem(test)
#preds <- predict_selection_ensemble(, test_data$data)
library(M4metaresults)
preds <- predict_selection_ensemble(model_M4, test_data$data)
test <- ensemble_forecast(preds, test)
length_cr_test <- length(test) - length(test_inds)
cr_test <- tail(test, length_cr_test)
M4_test <- head(test, length(test_inds))
# measuring errors on CheckRisk dataset ####
cr_error_table <- data.frame(series_name = character(),
meta_mape = double(),
rw_drift_mape = double(),
arima_mape = double(),
ets_mape = double(),
nn_mape = double(),
tbats_mape = double(),
stlm_mape = double(),
thetaf_mape = double(),
naive_mape = double(),
snaive_mape = double())
for (i in 1:length_cr_test){
series <- cr_test[[i]]
# plotForecastVsActual(series)
series_frame <- calcMDapes(series)
cr_error_table <- rbind(cr_error_table, series_frame)
}
# measuring errors on all the M4 test ####
M4_error_table <- data.frame(series_name = character(),
meta_mape = double(),
rw_drift_mape = double(),
arima_mape = double(),
ets_mape = double(),
nn_mape = double(),
tbats_mape = double(),
stlm_mape = double(),
thetaf_mape = double(),
naive_mape = double(),
snaive_mape = double())
for (i in 1:length(M4_test)){
series <- M4_test[[i]]
series_frame <- calcMDapes(series)
M4_error_table <- rbind(M4_error_table, series_frame)
}
colMeans(Filter(is.numeric, cr_error_table))
colMeans(Filter(is.numeric, M4_error_table))
cr_test_summary
fin_test_summary
full_fin_test_summary <- summary_performance(preds, dataset = M4_test)
full_cr_test_summary <- summary_performance(preds, dataset = cr_test)
#M4_test_preds <- predict_selection_ensemble(model_M4, )
M4_test_data <- create_feat_classif_problem(M4_test)
M4_test_preds <- predict_selection_ensemble(model_M4, M4_test_data$data)
M4_test <- ensemble_forecast(M4_test_preds, M4_test)
M4_test_summary <- summary_performance(M4_test_preds, dataset = M4_test)
cr_full_test_preds <- predict_selection_ensemble(model_M4, cr_test_data$data)
cr_full_test <- ensemble_forecast(cr_full_test_preds, cr_test)
length(cr_test)
length(cr_full_test_preds)
cr_test_data <- create_feat_classif_problem(cr_test)
cr_full_test_preds <- predict_selection_ensemble(model_M4, cr_test_data$data)
306/9
cr_full_test <- ensemble_forecast(cr_full_test_preds, cr_test)
cr_full_test_summary <- summary_performance(cr_full_test, dataset = cr_full_test)
cr_full_test_summary <- summary_performance(cr_full_test_preds, dataset = cr_full_test)
fin_test_summary
cr_test_summary
M4_test_summary
cr_full_test_summary
library(M4metaresults)
data <- create_feat_classif_problem(submission_M4)
preds <- predict_selection_ensemble(model_M4, data$data)
replication_M4 <- ensemble_forecast(preds, submission_M4)
rep_summary <- summary_performance(preds, replication_M4)
rep_summary <- summary_performance(preds, dataset = replication_M4)
replication_M4[[1]]
library(M4metaresults)
data <- create_feat_classif_problem(submission_M4)
preds <- predict_selection_ensemble(model_M4, data$data)
submission_M4 <- ensemble_forecast(preds, submission_M4)
rep_summary <- summary_performance(preds, dataset = submission_M4)
submission_M4 <- temp_holdout(submission_M4)
data <- create_feat_classif_problem(submission_M4)
preds <- predict_selection_ensemble(model_M4, data$data)
submission_M4 <- ensemble_forecast(preds, submission_M4)
rep_summary <- summary_performance(preds, dataset = submission_M4)
submission_M4[[1]]
submission_M4 <- calc_errors(submission_M4)
submission_M4[[1]]
M4_test_weekly <- M4_test[which(sapply(M4_test, function(series)(series$period == "Weekly")||(series$period == "Daily")))]
length_M4_weekly <- length(M4_test_weekly)
M4_error_table_weekly <- data.frame(series_name = character(),
meta_mape = double(),
rw_drift_mape = double(),
arima_mape = double(),
ets_mape = double(),
nn_mape = double(),
tbats_mape = double(),
stlm_mape = double(),
thetaf_mape = double(),
naive_mape = double(),
snaive_mape = double())
for (i in 1:length_M4_weekly){
series <- M4_test_weekly[[i]]
# plotForecastVsActual(series)
series_frame <- calcMapes(series)
M4_error_table_weekly <- rbind(M4_error_table_weekly, series_frame)
}
colMeans(Filter(is.numeric, M4_error_table_weekly))
colMeans(Filter(is.numeric, cr_error_table))
length(M4_test_weekly)
length(M4_test)
xgb_params
xgb_params$History
dim(xgb_params$History)
xgb_params$History
install.packages("mclust")
library(mclust)
?Mclust()
xgb_params$History[,2:5]
typeof(xgb_params$History[,2:5])
gmm_fit <- Mclust(xgb_params$History[,2:5])
summary(gmm_fit)
gmm_fit$data
gmm_fit$modelName
gmm_fit$n
gmm_fit$d
gmm_fit$G
gmm_fit$df
gmm_fit$parameters$mean
?xgboost::xgboost()
gmm_fit$classification
gmm_fit$uncertainty
hclust_fit <- hclust(xgb_params$History[,2:5])
xgb_params$History[,2:5]
?hclust
hist_data <- xgb_params$History[,2:5]
hist_dist <- dist(hist_data)
?dist
dist
hist_dist
dim(hist_dist)
h_fit <- hclust(hist_dist)
h_fit
plot(h_fit)
gmm_fit$parameters$mean
?xgboost::xgboost()
xgb_params$Best_Par
gmm_fit$parameters$pro
#hist_data <- xgb_params$History[,c(2:5,7)]
xgb_params$History[,c(2:5,7)]
names(xgb_params$History)
hist_data <- xgb_params$History[,c(2:5,7)]
gmm_fit <- Mclust(hist_data)
hist_dist <- dist(hist_data)
h_fit <- hclust(hist_dist)
summary(gmm_fit)
plot(h_fit)
gmm_fit$parameters$mean
?xgboost::xgboost()
xgb_params$History
apply(xgb_params$History, 2, sd)
apply(xgb_params$History, 2, mean)
gmm_fit$parameters$variance
gmm_fit$parameters$mean
?ggplot
gmm_fit$parameters$variance$G
gmm_fit$parameters$variance$sigma
ggplot(gmm_fit$parameters$variance$sigma)
library(ggplot)
install.packages("ggplot")
install.packages("ggplot")
install.packages("ggplot")
install.packages("ggplot2")
install.packages("ggplot2")
library(ggplot2)
ggplot(gmm_fit$parameters$variance$sigma)
ggplot(gmm_fit$parameters$mean)
gmm_fit$parameters$mean
t(gmm_fit$parameters$mean)
as.data.frame(t(gmm_fit$parameters$mean))
ggplot(as.data.frame(t(gmm_fit$parameters$mean)))
ggplot(as.data.frame(t(gmm_fit$parameters$mean)))
?facet_grid()
t <- ggplot(as.data.frame(t(gmm_fit$parameters$mean)))
t + facet_grid(rows=1:4)
t + facet_grid(1:4)
t + facet_grid(.)
drv
as.data.frame(gmm_fit$parameters$mean)
t <- ggplot(as.data.frame(gmm_fit$parameters$mean))
gmm_fit$parameters$variance
gmm_fit$parameters$variance$sigma
gmm_fit$parameters$variance
gmm_fit$parameters$variance$sigma
gmm_fit$parameters$variance$sigma[[1]]
dim(gmm_fit$parameters$variance$sigma)
gmm_fit$parameters$variance$sigma[1,1,
]
as.data.frame(gmm_fit$parameters$mean)
pd <- as.data.frame(gmm_fit$parameters$mean)
pdf <- as.data.frame(gmm_fit$parameters$mean)
pdf
pdf[,1
]
pdf[1,]
pdf[5,]
pdf[6,]
pdf[6,] = c("max_depth_var", gmm_fit$parameters$variance$sigma[1,1,])
cbind(pdf, gmm_fit$parameters$variance$sigma[1,1,])
rbind(pdf, gmm_fit$parameters$variance$sigma[1,1,])
pdf
pdf["max_depth",]
pdf["eta",]
pdf <- as.data.frame(gmm_fit$parameters$mean)
pdf
pdf["max_depth_var",] = gmm_fit$parameters$variance$sigma[1,1,]
pdf
pdf["eta_var",] = gmm_fit$parameters$variance$sigma[2,2,]
pdf["subsample_var",] = gmm_fit$parameters$variance$sigma[3,3,]
pdf["colsubsample_bytree_var",] = gmm_fit$parameters$variance$sigma[3,3,]
pdf["Value_var",] = gmm_fit$parameters$variance$sigma[3,3,]
pdf
pdf["colsubsample_bytree_var",] = gmm_fit$parameters$variance$sigma[4,4,]
pdf["Value_var",] = gmm_fit$parameters$variance$sigma[5,5,]
pdf
t <- ggplot(pdf)
t + facet_grid(~.V1)
t + facet_grid(~.max_depth)
data <- iris %>% select(Species, Sepal.Length)
my_sum <- data %>%
group_by(Species) %>%
summarise(
n=n(),
mean=mean(Sepal.Length),
sd=sd(Sepal.Length)
) %>%
mutate( se=sd/sqrt(n))  %>%
mutate( ic=se * qt((1-0.05)/2 + .5, n-1))
my_sum
ggplot(my_sum) +
geom_bar( aes(x=Species, y=mean), stat="identity", fill="forestgreen", alpha=0.5) +
geom_errorbar( aes(x=Species, ymin=mean-se, ymax=mean+se), width=0.4, colour="orange", alpha=0.9, size=1.5) +
ggtitle("using standard error")
t(pdf)
pdf <- t(pdf)
ggplot(t) + geom_bar( aes(y=max_depth), stat="identity", fill="forestgreen", alpha = 0.5)
ggplot(pdf) + geom_bar( aes(y=max_depth), stat="identity", fill="forestgreen", alpha = 0.5)
typeof(pdf)
pdf
as_tibble(pdf)
pdf["max_depth"]
pdf <- as_tibble(pdf)
pdf
pdf$cluster = 1:4
pdf
ggplot(pdf) + geom_bar( aes(x=cluster, y=max_depth), stat="identity", fill="forestgreen", alpha = 0.5)
ggplot(my_sum) +
geom_bar( aes(x=Species, y=mean), stat="identity", fill="forestgreen", alpha=0.5) +
geom_errorbar( aes(x=Species, ymin=mean-se, ymax=mean+se), width=0.4, colour="orange", alpha=0.9, size=1.5) +
ggtitle("using standard error")
ggplot(pdf) + geom_bar( aes(x=cluster, y=max_depth), stat="identity", fill="forestgreen", alpha = 0.5) +
geom_errorbar( aes(x=cluster, ymin=max_depth-sqrt(max_depth_var/106), ymax=max_depth+sqrt(max_depth_var/106)), width=0.4, colour="orange", alpha=0.9, size=1.5) + ggtitle("using standard error")
par(mfrow=c(5,1))
ggplot(pdf) + geom_bar( aes(x=cluster, y=max_depth), stat="identity", fill="forestgreen", alpha = 0.5) +
geom_errorbar( aes(x=cluster, ymin=max_depth-sqrt(max_depth_var/106), ymax=max_depth+sqrt(max_depth_var/106)), width=0.4, colour="orange", alpha=0.9, size=1.5) + ggtitle("using standard error")
ggplot(pdf) + geom_bar( aes(x=cluster, y=eta), stat="identity", fill="forestgreen", alpha = 0.5) +
geom_errorbar( aes(x=cluster, ymin=eta-sqrt(eta_var/106), ymax=eta+sqrt(eta_var/106)), width=0.4, colour="orange", alpha=0.9, size=1.5) + ggtitle("using standard error")
ggplot(pdf) + geom_bar( aes(x=cluster, y=subsample), stat="identity", fill="forestgreen", alpha = 0.5) +
geom_errorbar( aes(x=cluster, ymin=subsample-sqrt(subsample_var/106), ymax=subsample+sqrt(subsample_var/106)), width=0.4, colour="orange", alpha=0.9, size=1.5) + ggtitle("using standard error")
ggplot(pdf) + geom_bar( aes(x=cluster, y=colsample_bytree), stat="identity", fill="forestgreen", alpha = 0.5) +
geom_errorbar( aes(x=cluster, ymin=colsample_bytree-sqrt(colsample_bytree_var/106), ymax=colsample_bytree+sqrt(colsample_bytree_var/106)), width=0.4, colour="orange", alpha=0.9, size=1.5) + ggtitle("using standard error")
ggplot(pdf) + geom_bar( aes(x=cluster, y=colsubsample_bytree), stat="identity", fill="forestgreen", alpha = 0.5) +
geom_errorbar( aes(x=cluster, ymin=colsubsample_bytree-sqrt(colsubsample_bytree_var/106), ymax=colsubsample_bytree+sqrt(colsubsample_bytree_var/106)), width=0.4, colour="orange", alpha=0.9, size=1.5) + ggtitle("using standard error")
ggplot(pdf) + geom_bar( aes(x=cluster, y=colsample_bytree), stat="identity", fill="forestgreen", alpha = 0.5) +
geom_errorbar( aes(x=cluster, ymin=colsample_bytree-sqrt(colsubsample_bytree_var/106), ymax=colsample_bytree+sqrt(colsubsample_bytree_var/106)), width=0.4, colour="orange", alpha=0.9, size=1.5) + ggtitle("using standard error")
pdf
ggplot(pdf) + geom_bar( aes(x=cluster, y=Value), stat="identity", fill="forestgreen", alpha = 0.5) +
geom_errorbar( aes(x=cluster, ymin=Value-sqrt(Value_var/106), ymax=Value+sqrt(Value_var/106)), width=0.4, colour="orange", alpha=0.9, size=1.5) + ggtitle("using standard error")
ggplot(pdf) + geom_bar( aes(x=cluster, y=-Value), stat="identity", fill="forestgreen", alpha = 0.5) +
geom_errorbar( aes(x=cluster, ymin=-Value-sqrt(Value_var/106), ymax=-Value+sqrt(Value_var/106)), width=0.4, colour="orange", alpha=0.9, size=1.5) + ggtitle("using standard error")
gmm_fit$parameters$variance$sigma
?gmm_fit
typeof(gmm_fit)
?Mclust
gmm_fit$modelName
gmm_fit <- Mclust(hist_data, modelNames = "VVV")
gmm_fit
summary(gmm_fit)
gmm_fit$parameters$mean
gmm_fit$parameters$variance$sigma
install.packages("keras")
library(keras)
install_keras()
fashion_mnist <- dataset_fashion_mnist()
c(test_images, test_labels)
fashion_mnist$train
fashion_mnist$train$x
dim(fashion_mnist$train$x)
class_names = c('T-shirt/top',
'Trouser',
'Pullover',
'Dress',
'Coat',
'Sandal',
'Shirt',
'Sneaker',
'Bag',
'Ankle boot')
c(train_images, train_labels) %<-% fashion_mnist$train
train_images
c(test_images, test_labels) %<-% fashion_mnist$test
library(tidyr)
library(ggplot2)
install.packages("tidyr")
library(tidyr)
library(ggplot2)
image_1 <- as.data.frame(train_images[1, , ])
image_1
colnames(image_1) <- seq_len(ncol(image_1))
image_1
image_1$y <- seq_len(nrow(image_1))
image_1
image_1 <- gather(image_1, "x", "value", -y)
image_1
image_1$x <- as.integer(image_1$x)
image_1
ggplot(image_1, aes(x = x, y = y, fill = value)) +
geom_tile() +
scale_fill_gradient(low = "white", high = "black", na.value = NA) +
scale_y_reverse() +
theme_minimal() +
theme(panel.grid = element_blank())   +
theme(aspect.ratio = 1) +
xlab("") +
ylab("")
train_images <- train_images / 255
test_images <- test_images / 255
par(mfcol=c(5,5))
par(mar=c(0, 0, 1.5, 0), xaxs='i', yaxs='i')
for (i in 1:25) {
img <- train_images[i, , ]
img <- t(apply(img, 2, rev))
image(1:28, 1:28, img, col = gray((0:255)/255), xaxt = 'n', yaxt = 'n',
main = paste(class_names[train_labels[i] + 1]))
}
model <- keras_model_sequential()
model %>%
layer_flatten(input_shape = c(28, 28)) %>%
layer_dense(units = 128, activation = 'relu') %>%
layer_dense(units = 10, activation = 'softmax')
model %>% compile(
optimizer = 'adam',
loss = 'sparse_categorical_crossentropy',
metrics = c('accuracy')
)
summary(model)
summary(model)
model %>% fit(train_images, train_labels, epochs = 5)
?%>%
?"%>%"
score <- evaluate(model, test_images, test_labels)
score <- model %>% evaluate(test_images, test_labels)
score
predictions <- model %>% predict(test_images)
predictions
predictions[1, ]
which.max(predictions[1, ])
class_names[[10]]
class_pred <- predict_classes(model, test_images)
class_pred
par(mfcol=c(5,5))
par(mar=c(0, 0, 1.5, 0), xaxs='i', yaxs='i')
for (i in 1:25) {
img <- test_images[i, , ]
img <- t(apply(img, 2, rev))
# subtract 1 as labels go from 0 to 9
predicted_label <- which.max(predictions[i, ]) - 1
true_label <- test_labels[i]
if (predicted_label == true_label) {
color <- '#008800'
} else {
color <- '#bb0000'
}
image(1:28, 1:28, img, col = gray((0:255)/255), xaxt = 'n', yaxt = 'n',
main = paste0(class_names[predicted_label + 1], " (",
class_names[true_label + 1], ")"),
col.main = color)
}
img <- test_images[1, , , drop = FALSE]
dim(img)
predictions <- predict(model, img)
predictions
sum(predictions)
prediction <- predictions[1, ] - 1
prediction
which.max(prediction)
boston_housing <- dataset_boston_housing()
c(train_data, train_labels) <- boston_housing$train
?"%<-%"
c(train_data, train_labels) %<-% boston_housing$train # multiple assignment operator
c(test_data, test_labels) %<-% boston_housing$test
paste0("Training entries: ", length(train_data), ", labels: ", length(train_labels))
train_data[1, ] # Display sample features, notice the different scales
library(tibble)
train_df <- as_tibble(train_data)
column_names <- c('CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT')
colnames(train_df) <- column_names
train_df
train_labels[1:10]
# Normalize training data
train_data <- scale(train_data)
?scale
train_data
typeof(train_data)
dim(train_data)
# Use means and standard deviations from training set to normalize test set
col_means_train <- attr(train_data, "scaled:center")
col_stddevs_train <- attr(train_data, "scaled:scale")
test_data <- scale(test_data, center = col_means_train, scale = col_stddevs_train)
col_means_train
?attr
train_data
attr(train_data)
attributes(train_data)
build_model <- function() {
model <- keras_model_sequential() %>%
layer_dense(units = 64, activation = "relu",
input_shape = dim(train_data)[2]) %>%
layer_dense(units = 64, activation = "relu") %>%
layer_dense(units = 1)
model %>% compile(
loss = "mse",
optimizer = optimizer_rmsprop(),
metrics = list("mean_absolute_error")
)
model
}
model <- build_model()
summary(model)
# Display training progress by printing a single dot for each completed epoch.
print_dot_callback <- callback_lambda(
on_epoch_end = function(epoch, logs) {
if (epoch %% 80 == 0) cat("\n")
cat(".")
}
)
typeof(print_dot_callback)
?callback_lambda
epochs <- 500
history <- fit(model, train_data, train_labels, epochs = epochs,
validation_split = 0.2, verbose = 0,  callbacks = list(print_dot_callback))
history
plot(history, metrics = "mean_absolute_error", smooth = FALSE) + coord_cartesian(ylim = c(0, 5))
# The patience parameter is the amount of epochs to check for improvement.
early_stop <- callback_early_stopping(monitor = "val_loss", patience = 20)
model <- build_model()
history <- fit(model, train_data, train_labels, epochs = epochs,
validation_split = 0.2, verbose = 0, callbacks = list(early_stop, print_dot_callback))
history
plot(history, metrics = "mean_absolute_error", smooth = FALSE) + coord_cartesian(ylim = c(0, 5))
plot(history, metrics = "mean_absolute_error", smooth = FALSE) + coord_cartesian(xlim = c(0, 150), ylim = c(0, 5))
c(loss, mae) %<-% evaluate(model, test_data, test_labels, verbose = 0)
paste0("Mean absolute error on test set: $", sprintf("%.2f", mae * 1000))
test_predictions <- predict(model, test_data)
test_predictions[ , 1]
imdb <- load_imdb(num_words = 500, maxlen = 100)
library(kerasR)
install.packages("kerasR")
library(kerasR)
imdb <- load_imdb(num_words = 500, maxlen = 100)
